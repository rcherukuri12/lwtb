{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "A logistic regression learning algorithm example using TensorFlow library.\n",
    "Note:- Logistic regression( this word is historical accident..it is really classification)\n",
    "This program also teaches how to add test metrics ROC and probability distribution to tensorboard.\n",
    "'''\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "\n",
    "# Import cancer data\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# functions to read input \n",
    "def read_cancer_data():\n",
    "    cancer_data = load_breast_cancer()\n",
    "    features = np.array(cancer_data.data)\n",
    "    labels = np.array(cancer_data.target)\n",
    "    return features, labels\n",
    "def feature_normalize(dataset):\n",
    "    mu = np.mean(dataset,axis=0)\n",
    "    sigma = np.std(dataset,axis=0)\n",
    "    return (dataset - mu)/sigma\n",
    "def append_bias_reshape(features,labels):\n",
    "    n_training_samples = features.shape[0]\n",
    "    n_dim = features.shape[1]\n",
    "    f = np.reshape(np.c_[np.ones(n_training_samples),features],[n_training_samples,n_dim + 1])\n",
    "    l = np.reshape(labels,[n_training_samples,1])\n",
    "    return f, l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features,labels = read_cancer_data()\n",
    "normalized_features = feature_normalize(features)\n",
    "f, l = append_bias_reshape(normalized_features,labels)\n",
    "n_dim = f.shape[1]\n",
    "train_x, test_x, train_y, test_y = train_test_split(f, l, test_size=0.80, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.01\n",
    "training_epochs = 1000\n",
    "logs_path=\"/tmp/logs/3/1\"\n",
    "\n",
    "# tf Graph Input\n",
    "with tf.name_scope('input'):\n",
    "    x = tf.placeholder(tf.float32,[None,n_dim])\n",
    "    y = tf.placeholder(tf.float32,[None,1])\n",
    "    W = tf.Variable(tf.truncated_normal([n_dim, 1]))\n",
    "    tf.summary.histogram(\"Weights\",W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Construct model\n",
    "with tf.name_scope('model'):\n",
    "    layer1 = tf.matmul(x, W)\n",
    "    pred =  tf.nn.sigmoid(layer1) # sigmoid activation\n",
    "    # Minimize error using logistic regression\n",
    "    cost = tf.reduce_mean(tf.reduce_sum((-y * tf.log(pred)) - ((1 - y) * tf.log(1 - pred)), reduction_indices=[1]))\n",
    "    tf.summary.scalar('cost',cost)\n",
    "    #tf.summary.histogram('pred',pred)\n",
    "    summary_op = tf.summary.merge_all()\n",
    "    # Gradient Descent\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0050 cost= 0.727610886\n",
      "Epoch: 0100 cost= 0.524173200\n",
      "Epoch: 0150 cost= 0.425240457\n",
      "Epoch: 0200 cost= 0.366862983\n",
      "Epoch: 0250 cost= 0.328748077\n",
      "Epoch: 0300 cost= 0.302088737\n",
      "Epoch: 0350 cost= 0.282445014\n",
      "Epoch: 0400 cost= 0.267359734\n",
      "Epoch: 0450 cost= 0.255376667\n",
      "Epoch: 0500 cost= 0.245585859\n",
      "Epoch: 0550 cost= 0.237393558\n",
      "Epoch: 0600 cost= 0.230398655\n",
      "Epoch: 0650 cost= 0.224322081\n",
      "Epoch: 0700 cost= 0.218964666\n",
      "Epoch: 0750 cost= 0.214180797\n",
      "Epoch: 0800 cost= 0.209862262\n",
      "Epoch: 0850 cost= 0.205926567\n",
      "Epoch: 0900 cost= 0.202310383\n",
      "Epoch: 0950 cost= 0.198963940\n",
      "Epoch: 1000 cost= 0.195847809\n",
      "Optimization Finished!\n",
      "AUC: 0.964914831741\n"
     ]
    }
   ],
   "source": [
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    # create log writer object\n",
    "    writer = tf.summary.FileWriter(logs_path,sess.graph)\n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0.\n",
    "        # Run optimization op (backprop) and cost op (to get loss value)\n",
    "        _, c,summary = sess.run([optimizer, cost,summary_op], feed_dict={x: train_x, y: train_y})\n",
    "        # Compute average loss\n",
    "        avg_cost += c \n",
    "        writer.add_summary(summary,(epoch+1)*100)\n",
    "        # Display logs per epoch step\n",
    "        if (epoch+1) % 50 == 0:\n",
    "            print(\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(avg_cost))\n",
    "    print(\"Optimization Finished!\")\n",
    "    writer.flush()\n",
    "    \n",
    "    # we are adding additional histogram summaries here...\n",
    "    pred_summary = tf.summary.histogram(\"prediction\",pred)\n",
    "    merged = tf.summary.merge([pred_summary])\n",
    "    y_pred,ss = sess.run([pred,merged], feed_dict={x: test_x, y: test_y})\n",
    "    writer.add_summary(ss)\n",
    "    writer.flush()\n",
    "    print (\"AUC:\",sk.metrics.roc_auc_score(test_y, y_pred))\n",
    "    fpr, tpr, thresholds = sk.metrics.roc_curve(test_y, y_pred)\n",
    "    # we are adding ROC here\n",
    "    total = len(fpr)\n",
    "    for idx in range(total):\n",
    "        summt = tf.Summary()\n",
    "        summt.value.add(tag=\"ROC\", simple_value = tpr[idx])\n",
    "        writer.add_summary (summt, fpr[idx] * 100) #act as global_step\n",
    "        writer.flush ()\n",
    "    writer.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
